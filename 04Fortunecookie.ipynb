{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Written as part of https://www.scrapehero.com/how-to-scrape-amazon-product-reviews-using-python/\t\t\n",
    "import nltk\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import pdb\n",
    "# import plotly.plotly as py\n",
    "# import plotly.graph_objs as go\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics, cross_validation  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from lxml import html  \n",
    "\n",
    "import requests\n",
    "import json,re\n",
    "from dateutil import parser as dateparser\n",
    "from time import sleep\n",
    "\n",
    "from gensim import models\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import pickle\n",
    "\n",
    "# import json\n",
    "# from pprint import pprint\n",
    "# import re\n",
    "# import pandas as pd\n",
    "\n",
    "def ParseReviews(asin):\n",
    "\t# Added Retrying \n",
    "\tfor i in range(5):\n",
    "\t\ttry:\n",
    "\t\t\t#This script has only been tested with Amazon.com\n",
    "\t\t\tamazon_url  = 'http://www.amazon.com/dp/'+asin\n",
    "\t\t\t# Add some recent user agent to prevent amazon from blocking the request \n",
    "\t\t\t# Find some chrome user agent strings  here https://udger.com/resources/ua-list/browser-detail?browser=Chrome\n",
    "\t\t\theaders = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.90 Safari/537.36'}\n",
    "\t\t\tpage = requests.get(amazon_url,headers = headers)\n",
    "\t\t\tpage_response = page.text\n",
    "\n",
    "\t\t\tparser = html.fromstring(page_response)\n",
    "\t\t\tXPATH_AGGREGATE = '//span[@id=\"acrCustomerReviewText\"]'\n",
    "\t\t\tXPATH_REVIEW_SECTION_1 = '//div[contains(@id,\"reviews-summary\")]'\n",
    "\t\t\tXPATH_REVIEW_SECTION_2 = '//div[@data-hook=\"review\"]'\n",
    "\n",
    "\t\t\tXPATH_AGGREGATE_RATING = '//table[@id=\"histogramTable\"]//tr'\n",
    "\t\t\tXPATH_PRODUCT_NAME = '//h1//span[@id=\"productTitle\"]//text()'\n",
    "\t\t\tXPATH_PRODUCT_PRICE  = '//span[@id=\"priceblock_ourprice\"]/text()'\n",
    "\t\t\tXPATH_CATEGORY = '//a[@class=\"a-link-normal a-color-tertiary\"]/text()'\n",
    "            \n",
    "\t\t\traw_product_price = parser.xpath(XPATH_PRODUCT_PRICE)\n",
    "\t\t\tproduct_price = ''.join(raw_product_price).replace(',','')\n",
    "\t\t\traw_product_name = parser.xpath(XPATH_PRODUCT_NAME)\n",
    "\t\t\tproduct_name = ''.join(raw_product_name).strip()\n",
    "\t\t\traw_categories=parser.xpath(XPATH_CATEGORY)\n",
    "\t\t\tcategories=''.join(raw_categories).replace('\\n            \\n            ',',').strip()\n",
    "# \t\t\tcategories=categories1.strip().split(',')\n",
    "\t\t\ttotal_ratings  = parser.xpath(XPATH_AGGREGATE_RATING)\n",
    "\t\t\treviews = parser.xpath(XPATH_REVIEW_SECTION_1)\n",
    "\t\t\tif not reviews:\n",
    "\t\t\t\treviews = parser.xpath(XPATH_REVIEW_SECTION_2)\n",
    "\t\t\tratings_dict = {}\n",
    "\t\t\treviews_list = []\n",
    "\t\t\t\n",
    "\t\t\tif not reviews:\n",
    "\t\t\t\traise ValueError('unable to find reviews in page')\n",
    "\n",
    "\t\t\t#grabing the rating  section in product page\n",
    "\t\t\tfor ratings in total_ratings:\n",
    "\t\t\t\textracted_rating = ratings.xpath('./td//a//text()')\n",
    "\t\t\t\tif extracted_rating:\n",
    "\t\t\t\t\trating_key = extracted_rating[0] \n",
    "\t\t\t\t\traw_raing_value = extracted_rating[1]\n",
    "\t\t\t\t\trating_value = raw_raing_value\n",
    "\t\t\t\t\tif rating_key:\n",
    "\t\t\t\t\t\tratings_dict.update({rating_key:rating_value})\n",
    "\t\t\t#Parsing individual reviews\n",
    "\t\t\tfor review in reviews:\n",
    "\t\t\t\tXPATH_RATING  = './/i[@data-hook=\"review-star-rating\"]//text()'\n",
    "\t\t\t\tXPATH_REVIEW_HEADER = './/a[@data-hook=\"review-title\"]//text()'\n",
    "\t\t\t\tXPATH_REVIEW_POSTED_DATE = './/a[contains(@href,\"/profile/\")]/parent::span/following-sibling::span/text()'\n",
    "\t\t\t\tXPATH_REVIEW_TEXT_1 = './/div[@data-hook=\"review-collapsed\"]//text()'\n",
    "\t\t\t\tXPATH_REVIEW_TEXT_2 = './/div//span[@data-action=\"columnbalancing-showfullreview\"]/@data-columnbalancing-showfullreview'\n",
    "\t\t\t\tXPATH_REVIEW_COMMENTS = './/span[@data-hook=\"review-comment\"]//text()'\n",
    "\t\t\t\tXPATH_AUTHOR  = './/a[contains(@href,\"/profile/\")]/parent::span//text()'\n",
    "\t\t\t\tXPATH_REVIEW_TEXT_3  = './/div[contains(@id,\"dpReviews\")]/div/text()'\n",
    "\t\t\t\traw_review_author = review.xpath(XPATH_AUTHOR)\n",
    "\t\t\t\traw_review_rating = review.xpath(XPATH_RATING)\n",
    "\t\t\t\traw_review_header = review.xpath(XPATH_REVIEW_HEADER)\n",
    "\t\t\t\traw_review_posted_date = review.xpath(XPATH_REVIEW_POSTED_DATE)\n",
    "\t\t\t\traw_review_text1 = review.xpath(XPATH_REVIEW_TEXT_1)\n",
    "\t\t\t\traw_review_text2 = review.xpath(XPATH_REVIEW_TEXT_2)\n",
    "\t\t\t\traw_review_text3 = review.xpath(XPATH_REVIEW_TEXT_3)\n",
    "\n",
    "\t\t\t\tauthor = ' '.join(' '.join(raw_review_author).split()).strip('By')\n",
    "\n",
    "\t\t\t\t#cleaning data\n",
    "\t\t\t\treview_rating = ''.join(raw_review_rating).replace('out of 5 stars','')\n",
    "\t\t\t\treview_header = ' '.join(' '.join(raw_review_header).split())\n",
    "\t\t\t\treview_posted_date = dateparser.parse(''.join(raw_review_posted_date)).strftime('%d %b %Y')\n",
    "\t\t\t\treview_text = ' '.join(' '.join(raw_review_text1).split())\n",
    "\n",
    "\t\t\t\t#grabbing hidden comments if present\n",
    "\t\t\t\tif raw_review_text2:\n",
    "\t\t\t\t\tjson_loaded_review_data = json.loads(raw_review_text2[0])\n",
    "\t\t\t\t\tjson_loaded_review_data_text = json_loaded_review_data['rest']\n",
    "\t\t\t\t\tcleaned_json_loaded_review_data_text = re.sub('<.*?>','',json_loaded_review_data_text)\n",
    "\t\t\t\t\tfull_review_text = review_text+cleaned_json_loaded_review_data_text\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tfull_review_text = review_text\n",
    "\t\t\t\tif not raw_review_text1:\n",
    "\t\t\t\t\tfull_review_text = ' '.join(' '.join(raw_review_text3).split())\n",
    "\n",
    "\t\t\t\traw_review_comments = review.xpath(XPATH_REVIEW_COMMENTS)\n",
    "\t\t\t\treview_comments = ''.join(raw_review_comments)\n",
    "\t\t\t\treview_comments = re.sub('[A-Za-z]','',review_comments).strip()\n",
    "\t\t\t\treview_dict = {\n",
    "\t\t\t\t\t\t\t\t\t'review_comment_count':review_comments,\n",
    "\t\t\t\t\t\t\t\t\t'review_text':full_review_text,\n",
    "\t\t\t\t\t\t\t\t\t'review_posted_date':review_posted_date,\n",
    "\t\t\t\t\t\t\t\t\t'review_header':review_header,\n",
    "\t\t\t\t\t\t\t\t\t'review_rating':review_rating,\n",
    "\t\t\t\t\t\t\t\t\t'review_author':author\n",
    "\n",
    "\t\t\t\t\t\t\t\t}\n",
    "\t\t\t\treviews_list.append(review_dict)\n",
    "\n",
    "\t\t\tdata = {\n",
    "\t\t\t\t\t\t'ratings':ratings_dict,\n",
    "\t\t\t\t\t\t'reviews':reviews_list,\n",
    "\t\t\t\t\t\t'url':amazon_url,\n",
    "\t\t\t\t\t\t'price':product_price,\n",
    "\t\t\t\t\t\t'name':product_name,\n",
    "\t\t\t\t\t\t'categories':categories    \n",
    "\t\t\t\t\t}\n",
    "\t\t\treturn data\n",
    "\t\texcept ValueError:\n",
    "\t\t\tprint \"Retrying to get the correct response\"\n",
    "\t\n",
    "\treturn {\"error\":\"failed to process the page\",\"asin\":asin}\n",
    "\t\t\t\n",
    "\n",
    "def ReadAsin(asinList):\n",
    "\t#Add your own ASINs here \n",
    "\tasinList = asinList\n",
    "\tscrapedData = []\n",
    "\tfor asin in asinList:\n",
    "\t\tprint \"Downloading and processing page http://www.amazon.com/dp/\"+asin\n",
    "\t\tscrapedData.append(ParseReviews(asin))\n",
    "\t\tsleep(5)\n",
    "\treturn scrapedData\n",
    "# \tf=open('newReview.json','w')\n",
    "# \tjson.dump(extracted_data,f,indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and processing page http://www.amazon.com/dp/B002KCO96C\n",
      "[{'ratings': {'2 star': '6%', '1 star': '10%', '4 star': '19%', '3 star': '10%', '5 star': '55%'}, 'name': 'Dirt Devil Vacuum Cleaner Simpli-Stik Lightweight Bagless Corded Stick and Handheld Vacuum SD20000RED', 'url': 'http://www.amazon.com/dp/B002KCO96C', 'price': '$18.99', 'reviews': [{'review_header': \"Great vacuum for people who don't care\", 'review_text': 'This is the perfect vacuum for all of us casual, type-B cleaners out there. I\\'ve had it for a year and it still runs as well as the first day I got. Do I clean rigorously with it every week? Of course not, I\\'m the type of person who buys a $20 vacuum. But it\\'s perfect for that special monthly once-over I give my apartment to feel like a decent human again. I use it on hardwood, carpet, rugs, the couch, my dog, whatever. Great for: - Cleaning up your two-bedroom apartment once a month before your parents come to visit - Sucking up all the hair up off the bathroom floor so you don\\'t have to mop (because who has time to mop) - Vacuuming your couch cushions because you love eating pizza on the couch (the handle also comes off to make this easier but it\\'s so lightweight that I\\'m like who cares, I just stand on the couch with the whole thing still intact) Not good for: - Cleaning up every week after your 6 children and 2 golden retrievers - The type of person who loves to \"entertain\" - Cleaning your 3 story house that is wall-to-wall carpet Bonus: - The cord is really long so not a lot of unplugging/replugging needs to happen (great if you\\'re lazy) - There are gizmos and gadgets like the handle pops off and there\\'s a skinny nozzle that you can attach if you want to create a more \"fancy\" vacuuming experience (I don\\'t bother because attaching/detaching stuff seems like a lot of work, but it could be fun for you) - It\\'s extremely lightweight which makes the thought of vacuuming 100 times easier since you don\\'t have the dreaded \"ugh I have to drag that giant monster out of the closet\" experience.', 'review_comment_count': '50+', 'review_posted_date': '10 Dec 2016', 'review_rating': '5.0 ', 'review_author': ' Lazy Lad'}, {'review_header': 'WIN! WIN!', 'review_text': \"This was probably the most awesome Christmas gift I could have ever given my 4 year old. She wanted a vacuum like mommy's. I looked at all of the toy vacuums and some how came across this beauty. The toy vacuums cost more and did less than this little dirt devil. It is the perfect height and weight for her. Instead of pretending to vacuum, she actually is vacuuming. WIN! WIN!\", 'review_comment_count': '14', 'review_posted_date': '10 Mar 2015', 'review_rating': '5.0 ', 'review_author': ' SneauxDayz'}, {'review_header': 'Powerful enough to handle fur from 2 shedding Huskies', 'review_text': \"I don't move anywhere without this vacuum. I've used it for 3+ years and can definitely say it works as well or better than bigger, more powerful household vacuums -- as long as you regularly empty the dirt cup and give the filter inside a good rinsing. I lived in with 2 massive Siberian Huskies who were blowing their coats, meaning piles, and piles, and piles of fur littered EVERYWHERE. This allowed me to clean up their daily shedding in a pinch, and even vacuum it from the dogs directly. The narrow attachment is great for cleaning up dirt and dust along the baseboards of a room, on windowsills, and corners.\", 'review_comment_count': '', 'review_posted_date': '26 Nov 2016', 'review_rating': '5.0 ', 'review_author': ' Jane Z'}, {'review_header': 'Clever Household Tool', 'review_text': 'I have to admit I did not have high expectations for this product. In fact, I figured I would probably end up returning it. However, now that I have owned and used this product for two months I feel it\\'s fair to say this is an exceptionally great product for the price and what it is configured to do. I would recommend this product. PLEASE NOTE: THIS IS NOT A NORMAL VACUUM! It is simply a day to day sweeper that can do small jobs such as corners, small area rugs, entry ways, and some hard to reach areas. THIS IS A \"DUST BUSTER\" with a floor attachment, handle and corner attachment. The handle is a perfect height/length for me (5\\'5\"). It is not battery operated or rechargeable like a Swiffer Sweeper, but the cord is quite long and I have no trouble reaching the top of the stairs with it. The dirt container is bagless and can easily be emptied with the click of a release button. The floor attachment and corner/crevice attachment are also easily removed or connected as they fit into the end of the main unit (dust buster). It is not extremely loud but it isn\\'t quiet either. The suction power is perfect and powerful for bare floors and small area rugs. I find the suction is greater and does a better job than my swiffer sweeper. I do daily clean-ups with this stick vacuum and it picks up the fur from my two large weimaraners along with all the dirt, sand, and dust they carried in. Many reviews rated this vacuum low but I highly disagree. This product is fairly inexpensive and so for the price (I paid $16) I recommend you give it a shot. Hope this helps.', 'review_comment_count': '1', 'review_posted_date': '27 Dec 2015', 'review_rating': '4.0 ', 'review_author': ' Mrs. Hopefull'}, {'review_header': \"The best Bagless Stick Vacuum i've ever had! Very convenient to use!\", 'review_text': \"This Simpli-Stik Lightweight Bagless Stick Vacuum was so Awesome this has been very useful for me we had a Rainbow Vacuum which is big and heavy plus we only had a Small space so i don't wanna use that big,bulky and heavy Vacuum. This Vacuum was very light weight (3.8 lbs) convenient and very easy to use even my 8 years old Son is using this Vacuum. I liked that i can also convert this Vacuum as a Hand Vac and On-Board Crevice Tool which is i need the most to clean up the mess under the Couch and other tight spaces.The quality is great its very well made,sturdy and durable the Cord is long enough. Over all i was very impressed and satisfied with this Vacuum the only thing is it doesn't suck a bit bigger pieces on the floor this Vacuum only works with a small pieces if it gets a bit bigger pieces of food it will clog because the hole is not that Big like a regular Vacuum but anyway before using this on the Floor or Carpet i picked up the Bigger pieces first. However i liked this Simpli-Stik Lightweight Bagless Stick Vacuum i've been using it for 2 Weeks now and so far i don't experience any problems yet! 100% i will surely recommend this to everyone! Works great on the Floor or Carpet! Very worth it for the Price!\", 'review_comment_count': '', 'review_posted_date': '10 Jun 2016', 'review_rating': '5.0 ', 'review_author': ' PinkButterfl'}], 'categories': 'Home & Kitchen,    Vacuums & Floor Care,    Vacuums,     Stick Vacuums & Electric Brooms'}]\n"
     ]
    }
   ],
   "source": [
    "asinList=['B002KCO96C']\n",
    "\n",
    "scrapedData=ReadAsin(asinList)\n",
    "# print scrapedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home & Kitchen,    Vacuums & Floor Care,    Vacuums,     Stick Vacuums & Electric Brooms\n",
      "0    Home & Kitchen,    Vacuums & Floor Care,    Va...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "scrapedData0=scrapedData\n",
    "print scrapedData0[0]['categories']\n",
    "\n",
    "tags = pd.Series(scrapedData0[0]['categories']) \n",
    "tags = tags.rename(columns = lambda x : 'cat_' + str(x))\n",
    "# scrapedData=pd.concat([scrapedData0[:], tags[:]], axis=1)\n",
    "# print scrapedData\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetDataInput(scrapedData0):\n",
    "    metaList=[]\n",
    "    reviewList=[]\n",
    "    starList=['1 star', '2 star','3 star', '4 star', '5 star']\n",
    "    overall=0\n",
    "\n",
    "    tags=pd.Series()\n",
    "    for i in range(0,len(scrapedData)):\n",
    "        overall=0\n",
    "        asin=asinList[i]\n",
    "        price=re.sub('[!@#$%]', '', scrapedData[i]['price'])\n",
    "        for z in range(0,len(starList)):\n",
    "            if starList[z] in scrapedData[i]['ratings']:\n",
    "                overall=overall+(z+1)*float(re.sub('[!@#$%]', '',scrapedData[i]['ratings'][starList[z]]))/100\n",
    "        description=scrapedData[i]['name']\n",
    "        categories=pd.Series(scrapedData[i]['categories'])\n",
    "        metaList.append((asin,description,price,overall,categories))\n",
    "\n",
    "        for j in range(0,len(scrapedData[i]['reviews'])):\n",
    "            reviewText=scrapedData[i]['reviews'][j]['review_text']\n",
    "            reviewTime=scrapedData[i]['reviews'][j]['review_posted_date']\n",
    "            reviewList.append((asin,reviewTime,reviewText))\n",
    "\n",
    "    metaDfIn=pd.DataFrame(metaList,columns=['asin','description','price','overall','categories'])\n",
    "    reviewDfIn=pd.DataFrame(reviewList,columns=['asin','reviewTime','reviewText'])\n",
    "    dfIn=reviewDfIn.join(metaDfIn.set_index('asin'),on='asin')\n",
    "\n",
    "    #Categories \n",
    "#     tags = pd.Series(dfIn['categories']) \n",
    "#     print tags\n",
    "#     tags2 = tags.rename(columns = lambda x : 'cat_' + str(x))\n",
    "#     dfIn=pd.concat([dfIn[:], tags2[:]], axis=1)\n",
    "#     print list(dfIn)\n",
    "    \n",
    "    # extract 5 reviews \n",
    "\n",
    "    dfIn['reviewTime']=pd.to_datetime(dfIn['reviewTime'])\n",
    "    dfIns=dfIn.sort_values(['asin','reviewTime'],ascending=[True,True])\n",
    "    dfIn5=dfIns.groupby('asin').head(5).reset_index(drop=True)\n",
    "\n",
    "    dfIn5['lenReviewText']= dfIn5['reviewText'].str.len()\n",
    "    dfIn5['lenDescription']= dfIn5['description'].str.len()\n",
    "    dfIn5['lenReviewText']=dfIn5['lenReviewText'].fillna(0)\n",
    "    dfIn5['lenDescription']=dfIn5['lenDescription'].fillna(0)\n",
    "    dfIn5['lenReviewTextAvg']=dfIn5['lenReviewText'].groupby(dfIn5['asin']).transform(\"mean\")\n",
    "    dfIn5['lenDescriptionAvg']=dfIn5['lenDescription'].groupby(dfIn5['asin']).transform(\"mean\")\n",
    "\n",
    "    #Unix time 86400 seconds/ day \n",
    "    # list(dfIn5.columns.values)\n",
    "\n",
    "    # maxtime=dfIn5['unixReviewTime'].max()\n",
    "    dfIn5['numDaysPriorMax']=365\n",
    "    dfIn5=dfIn5.assign(\n",
    "        daysToFiveRev=-dfIn5.sort_values('reviewTime', ascending=True).groupby(['asin']).reviewTime.diff(-4).dt.days.fillna(0))\n",
    "\n",
    "    dfIn5['reviewText'] = dfIn5['reviewText'].apply(lambda x: x.encode('utf-8').strip())\n",
    "    dfIn5['allReview']=dfIn5.groupby(['asin'])['reviewText'].transform(lambda x: ', '.join(x))\n",
    "\n",
    "    dfIn51=dfIn5.groupby('asin').head(1).reset_index(drop=True)\n",
    "    dfIn51=dfIn51.fillna(0)\n",
    "\n",
    "    return dfIn51\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0    Home & Kitchen,    Vacuums & Floor Care, ...\n",
      "1    0    Home & Kitchen,    Vacuums & Floor Care, ...\n",
      "2    0    Home & Kitchen,    Vacuums & Floor Care, ...\n",
      "3    0    Home & Kitchen,    Vacuums & Floor Care, ...\n",
      "4    0    Home & Kitchen,    Vacuums & Floor Care, ...\n",
      "Name: categories, dtype: object\n",
      "['asin', 'reviewTime', 'reviewText', 'description', 'price', 'overall', 'categories', 0]\n",
      "         asin reviewTime                                         reviewText  \\\n",
      "0  B002KCO96C 2015-03-10  This was probably the most awesome Christmas g...   \n",
      "\n",
      "                                         description  price  overall  \\\n",
      "0  Dirt Devil Vacuum Cleaner Simpli-Stik Lightwei...  18.99     4.03   \n",
      "\n",
      "                                          categories  \\\n",
      "0  0    Home & Kitchen,    Vacuums & Floor Care, ...   \n",
      "\n",
      "                                                   0  lenReviewText  \\\n",
      "0  0    Home & Kitchen,    Vacuums & Floor Care, ...            378   \n",
      "\n",
      "   lenDescription  lenReviewTextAvg  lenDescriptionAvg  numDaysPriorMax  \\\n",
      "0             101            1082.2                101              365   \n",
      "\n",
      "   daysToFiveRev                                          allReview  \n",
      "0          641.0  This was probably the most awesome Christmas g...  \n"
     ]
    }
   ],
   "source": [
    "dataInput=GetDataInput(scrapedData)\n",
    "print dataInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RunDoc2Vec(dataInput):\n",
    "    model= models.Doc2Vec.load('my_model.doc2vec')\n",
    "    d2vtest=dataInput\n",
    "    d2vlist=[]\n",
    "    for i in range(0,len(d2vtest)):\n",
    "        line=d2vtest.iloc[i]['reviewText']\n",
    "        asin=d2vtest.iloc[i]['asin']\n",
    "        tokens = gensim.utils.to_unicode(line).split()\n",
    "        new_vector = model.infer_vector(tokens)\n",
    "        topSim = model.docvecs.most_similar([new_vector])[0][0]\n",
    "        secSim = model.docvecs.most_similar([new_vector])[1][0]\n",
    "        lowSim = model.docvecs.most_similar([new_vector])[2][0]\n",
    "        topSimSco = model.docvecs.most_similar([new_vector])[0][1]\n",
    "        secSimSco = model.docvecs.most_similar([new_vector])[1][1]\n",
    "        lowSimSco = model.docvecs.most_similar([new_vector])[2][1]\n",
    "        d2vlist.append((asin,topSim,secSim,lowSim,topSimSco,secSimSco,lowSim))\n",
    "        d2vresult=pd.DataFrame(d2vlist,columns=['asin','topSimilar','secSimilar','lowSimilar','scoSimHig','scoSimSec','scoSimLow'])\n",
    "    #https://gist.github.com/balajikvijayan/9f7ab00f9bfd0bf56b14\n",
    "\n",
    "    df_ml_d2v=pd.merge(d2vresult,d2vtest, on=['asin'])\n",
    "    df_ml_d2v['scoDifHigLow']=df_ml_d2v['scoSimHig']-df_ml_d2v['scoSimLow']\n",
    "\n",
    "    topDummy= pd.get_dummies(df_ml_d2v['topSimilar'], prefix='top')\n",
    "    df_ml_d2v = pd.concat([df_ml_d2v, topDummy], axis=1, join_axes=[df_ml_d2v.index])\n",
    "    return df_ml_d2v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RunML(mlData):\n",
    "    f = open('FortuneCookie.pickle', 'rb')\n",
    "    trained_logistic_regression_model = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    training_features = ['topSimilar','scoDifHigLow','lenReviewTextAvg','lenDescriptionAvg',\n",
    "                         'numDaysPriorMax','daysToFiveRev',\n",
    "                         'overall','price',\n",
    "                         'Canister Vacuums','Carpet Cleaners, Sweepers & Accessories','Handheld Vacuums',\n",
    "                         'Robotic Vacuums','Stick Vacuums & Electric Brooms','Upright Vacuums',\n",
    "                         'Bissell','Black &amp; Decker','Dirt Devil','Dyson','Electrolux',\n",
    "                         'EnviroCare','Eureka','Euro-Pro','FilterStream','GV','Green Label','Hoover','Infinuvo','Irobot',\n",
    "                         'Kenmore','Miele','Moneual','NEATO','Neato Robotics','Oreck','Oreck Merchandising LLC, us kitchen, OREBQ',\n",
    "                         'Ovente','P3','Panasonic','Robot Add-Ons','Sebo Vacuums',\n",
    "                         'Shark','Shop-Vac','Synergy','Techko Maid','The Bank Vacuum Company','Wrapables','iRobot']\n",
    "    target = 'rankCat'\n",
    "    \n",
    "    for i in training_features:\n",
    "        if i not in mlData:\n",
    "            mlData[i] = 0 \n",
    "    mlData['prediction']=trained_logistic_regression_model.predict(mlData[training_features])\n",
    "    return mlData\n",
    "    #     conf_matrix=confusion_matrix(test_y, test_x['prediction'])\n",
    "#     sns.heatmap(conf_matrix, annot=True)\n",
    "#     sns.plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and processing page http://www.amazon.com/dp/B002KCO96C\n",
      "Downloading and processing page http://www.amazon.com/dp/B006LXOJC0\n",
      "         ASIN                                               Name  \\\n",
      "0  B002KCO96C  Dirt Devil Vacuum Cleaner Simpli-Stik Lightwei...   \n",
      "1  B006LXOJC0  BLACK + DECKER CHV1410L 16V Cordless Lithium H...   \n",
      "\n",
      "  Date of first review  Time to five reviews (days)  Average length of review  \\\n",
      "0           2015-03-10                        641.0                    1082.2   \n",
      "1           2013-12-07                       1172.0                    1068.6   \n",
      "\n",
      "   Price  Sales Rank  \n",
      "0  18.99           0  \n",
      "1  54.21           0  \n"
     ]
    }
   ],
   "source": [
    "asinList=['B002KCO96C','B006LXOJC0']\n",
    "\n",
    "scrapedData=ReadAsin(asinList)\n",
    "dataInput=GetDataInput(scrapedData)\n",
    "mlData=RunDoc2Vec(dataInput)\n",
    "prediction=RunML(mlData) # 0=best seller, 1=mid, 2=low \n",
    "\n",
    "\n",
    "\n",
    "predList=[]\n",
    "for i in range(0,len(prediction)):\n",
    "    asin=prediction.iloc[i]['asin']\n",
    "    name=prediction.iloc[i]['description']\n",
    "    dateFirst=prediction.iloc[i]['reviewTime']\n",
    "    daysToFiveRev=prediction.iloc[i]['daysToFiveRev']\n",
    "    reviewLength=prediction.iloc[i]['lenReviewTextAvg']\n",
    "    price=prediction.iloc[i]['price']\n",
    "    predRankCat=prediction.iloc[i]['prediction']\n",
    "    predList.append((asin,name,dateFirst,daysToFiveRev,reviewLength,price,predRankCat))\n",
    "    predResult=pd.DataFrame(predList,columns=['ASIN','Name','Date of first review','Time to five reviews (days)', \n",
    "                                              'Average length of review', 'Price', 'Sales Rank'\n",
    "                                             ]) \n",
    "print predResult.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
